{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
       "    return false;\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.p3_ProcessLogger import ProcessLogger\n",
    "cell_log = ProcessLogger() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Project: Adopt a Drain\n",
    " * Author: James Wilfong, wilfongjt@gmail.com\n",
    " \n",
    "## Basics\n",
    "* data processed in a local clone of source-data \n",
    "* intermediate files are put into source-data repo\n",
    "* the final data.world data set name is the same as the raw-data file name\n",
    "* the source-data repo folders /raw-data, /clean-data, /notebook are updated during the process\n",
    "\n",
    "## Raw-data Process\n",
    "* input: raw-data/ \n",
    "* use python via jupyter notebook to manipulate data into usable file\n",
    "* update results to github\n",
    "* output: clean-data/\n",
    "\n",
    "## GIT Process\n",
    "* input: clean-data/\n",
    "* process: add, commit, push files from raw-data/, clean-data/, notebook/ folders\n",
    "* output: GitHub source-data repo\n",
    "\n",
    "## Data.World Process\n",
    "* input: GitHub source-data/clean-data/\n",
    "* process: transfer github clean-data/ to data.world\n",
    "* output: data.world\n",
    "\n",
    "## Table of Contents\n",
    "* [Introduction](#intro)\n",
    "\n",
    "* [Data Wrangling](#wrangling_steps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Flow Deprecated\n",
    "\n",
    "| Local      |   | GitHub     |   | Data.World.Test |   | Data.World.Prod |\n",
    "| :-         | :-| :-         | :-  | :-              | :-  | :- |\n",
    "| Curator    | > | raw-data   |   |                 |   |  |\n",
    "| Developer  | < | raw-data   |   |                 |   |  |\n",
    "|            | > | clean-data | > | test-data       |   |  | \n",
    "| Maintainer | < | clean-data |   |                 |   |  |\n",
    "|            | > |            |   |                 | > | open-data |\n",
    "| App(s)   | < |            |   |                 | < | open-data |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Jupyter Notebook\n",
    "Launch Jupyter Notebook from scripts/app-name folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='intro'></a>\n",
    "## Introduction\n",
    "* why adopt a drain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='prerequisites'></a>\n",
    "## Prerequisites\n",
    "* You should have a fresh copy of [citizenlabsgr/data.world](https://github.com/citizenlabsgr/data.world)\n",
    "\n",
    "* create [Github](#github) repository to hold raw data\n",
    "* create [Data World](#data-world) account\n",
    "* [Notebook Config](#notebook-config)\n",
    "* [Environment Variable Setup](#env-setup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='data-world'></a>\n",
    "## Dataworld\n",
    "* Set up an account\n",
    "* DW_AUTH_TOKEN value comes from your [data.world](https://data.world/) account-settings-advanced-Admin.\n",
    "* Application data is stored in data.world\n",
    "* A Data.world dataset is mostly read-only\n",
    "* A Data.world is updated via file replacement\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='github'></a>\n",
    "## Github\n",
    "\n",
    "* raw-data is loaded from the remote source-data repo on Github\n",
    "* raw-data is stored in the /raw-data folder of the source-data repo\n",
    "* raw-data is pushed to the remote source-data repo before running this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='env-setup'></a>\n",
    "## Environment Variable Setup\n",
    "\n",
    "* Create a file .env and put in the /scripts/<app-name>/ folder\n",
    "* .env does not get included in the github repository. Exclude .env from github in the .gitignore file\n",
    "* Add environment variables to .env file\n",
    "    * GH_URL=https://raw.githubusercontent.com/Wilfongjt/source-data/master/raw-data/\n",
    "    * DW_DB_URL=https://api.data.world/v0/datasets/wilfongjt/\n",
    "    * DW_USER=your-data-world-user-name\n",
    "    * DW_AUTH_TOKEN=dataworld-adm-token\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Load Packages\n",
       "* Load environment variables\n",
       "* Import third party packages\n",
       "* Import custom packages"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell_log.clear()\n",
    "cell_log.collect('## Load Packages')\n",
    "# import dotenv\n",
    "cell_log.collect('* Load environment variables')\n",
    "from settings import *\n",
    "import interface\n",
    "cell_log.collect('* Import third party packages')\n",
    "\n",
    "from datadotworld.client import _swagger\n",
    "# from datadotworld.client.api import RestApiError\n",
    "# import datadotworld as dw\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "import pprint\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import csv # read and write csv files\n",
    "from IPython.display import display, HTML\n",
    "from IPython.display import Markdown\n",
    "from pprint import pprint\n",
    "# import time\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "# convenience functions -- cleaning\n",
    "cell_log.collect('* Import custom packages')\n",
    "from lib.p3_CellCounts import CellCounts\n",
    "import lib.p3_clean as clean\n",
    "from lib.p3_configuration import get_configuration\n",
    "import lib.p3_explore as explore\n",
    "import lib.p3_gather as gather # gathering functions\n",
    "import lib.p3_helper_functions as helper\n",
    "import lib.p3_map as maps\n",
    "\n",
    "Markdown('''{}'''.format(cell_log.getMarkdown()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Helper Functions \n",
       "\n",
       "* get_app_name( script_folder_name )\n",
       "* get_repo_folder( script_folder_name )\n",
       "* get_raw_data_folder( script_folder_name )\n",
       "* get_clean_data_folder( script_folder_name )"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell_log.clear()\n",
    "cell_log.collect('## Helper Functions ')\n",
    "cell_log.collect('')\n",
    "cell_log.collect('* get_app_name( script_folder_name )')\n",
    "def get_app_name(scripts_path):\n",
    "    '''\n",
    "    returns application name from script path\n",
    "    '''\n",
    "    rc = ''\n",
    "    pth = scripts_path.split('/')\n",
    "    rc = pth[len(pth)-1]\n",
    "    return rc \n",
    "cell_log.collect('* get_repo_folder( script_folder_name )')\n",
    "def get_repo_folder(scripts_path):\n",
    "    '''\n",
    "    returns path to the repo folder from script path\n",
    "    '''\n",
    "    rc = ''\n",
    "    rc = scripts_path.replace('/' + get_app_name(scripts_path), '').replace('/scripts','')\n",
    "    return rc\n",
    "cell_log.collect('* get_raw_data_folder( script_folder_name )')\n",
    "def get_raw_data_folder(scripts_path):\n",
    "    '''\n",
    "    returns path to raw data from script path\n",
    "    '''\n",
    "    return get_repo_folder(scripts_path) + '/raw-data/' + get_app_name(scripts_path)\n",
    "cell_log.collect('* get_clean_data_folder( script_folder_name )')    \n",
    "def get_clean_data_folder(scripts_path):\n",
    "    '''\n",
    "    returns path to clean data from script path\n",
    "    '''\n",
    "    rc = get_repo_folder(scripts_path) + '/clean-data/' + get_app_name(scripts_path)\n",
    "    if not os.path.exists(rc):\n",
    "        os.makedirs(rc)\n",
    "    return rc\n",
    "def getSourceData(tblDef):\n",
    "    '''\n",
    "    returns the original raw data as pandas dataframe\n",
    "    '''\n",
    "    return pd.read_csv(tblDef[\"local_raw\"])\n",
    "Markdown('''{}'''.format(cell_log.getMarkdown()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /Users/jameswilfong/anaconda/lib/python3.6/site-packages\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 18.0 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: datadotworld[pandas] in /Users/jameswilfong/anaconda/lib/python3.6/site-packages\n",
      "Requirement already satisfied: tabulator<=1.4.1 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from datadotworld[pandas])\n",
      "Requirement already satisfied: urllib3<2.0a,>=1.15 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from datadotworld[pandas])\n",
      "Requirement already satisfied: click<7.0a,>=6.0 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from datadotworld[pandas])\n",
      "Requirement already satisfied: flake8<3.4.1a,>=2.6.0 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from datadotworld[pandas])\n",
      "Requirement already satisfied: datapackage<1.0a,>=0.8.8 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from datadotworld[pandas])\n",
      "Requirement already satisfied: requests<3.0a,>=2.0.0 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from datadotworld[pandas])\n",
      "Requirement already satisfied: certifi>=2017.04.17 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from datadotworld[pandas])\n",
      "Requirement already satisfied: python-dateutil<3.0a,>=2.6.0 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from datadotworld[pandas])\n",
      "Requirement already satisfied: six<2.0a,>=1.5.0 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from datadotworld[pandas])\n",
      "Requirement already satisfied: configparser<4.0a,>=3.5.0 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from datadotworld[pandas])\n",
      "Requirement already satisfied: jsontableschema<1.0a,>=0.10.0 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from datadotworld[pandas])\n",
      "Requirement already satisfied: pandas<1.0a; extra == \"pandas\" in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from datadotworld[pandas])\n",
      "Requirement already satisfied: openpyxl<3.0,>=2.4 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from tabulator<=1.4.1->datadotworld[pandas])\n",
      "Requirement already satisfied: unicodecsv<2.0,>=0.14 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from tabulator<=1.4.1->datadotworld[pandas])\n",
      "Requirement already satisfied: linear-tsv<2.0,>=1.0 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from tabulator<=1.4.1->datadotworld[pandas])\n",
      "Requirement already satisfied: ijson<3.0,>=2.0 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from tabulator<=1.4.1->datadotworld[pandas])\n",
      "Requirement already satisfied: jsonlines<2.0,>=1.1 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from tabulator<=1.4.1->datadotworld[pandas])\n",
      "Requirement already satisfied: sqlalchemy<2.0,>=1.1 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from tabulator<=1.4.1->datadotworld[pandas])\n",
      "Requirement already satisfied: xlrd<2.0,>=1.0 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from tabulator<=1.4.1->datadotworld[pandas])\n",
      "Requirement already satisfied: cchardet<2.0,>=1.0 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from tabulator<=1.4.1->datadotworld[pandas])\n",
      "Requirement already satisfied: mccabe<0.7.0,>=0.6.0 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from flake8<3.4.1a,>=2.6.0->datadotworld[pandas])\n",
      "Requirement already satisfied: pycodestyle<2.4.0,>=2.0.0 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from flake8<3.4.1a,>=2.6.0->datadotworld[pandas])\n",
      "Requirement already satisfied: pyflakes<1.6.0,>=1.5.0 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from flake8<3.4.1a,>=2.6.0->datadotworld[pandas])\n",
      "Requirement already satisfied: jsonschema<3.0a,>=2.5 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from datapackage<1.0a,>=0.8.8->datadotworld[pandas])\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from requests<3.0a,>=2.0.0->datadotworld[pandas])\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from requests<3.0a,>=2.0.0->datadotworld[pandas])\n",
      "Requirement already satisfied: rfc3986<1.0,>=0.4 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from jsontableschema<1.0a,>=0.10.0->datadotworld[pandas])\n",
      "Requirement already satisfied: isodate<1.0,>=0.5.4 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from jsontableschema<1.0a,>=0.10.0->datadotworld[pandas])\n",
      "Requirement already satisfied: future<1.0,>=0.15 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from jsontableschema<1.0a,>=0.10.0->datadotworld[pandas])\n",
      "Requirement already satisfied: pytz>=2011k in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from pandas<1.0a; extra == \"pandas\"->datadotworld[pandas])\n",
      "Requirement already satisfied: numpy>=1.7.0 in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from pandas<1.0a; extra == \"pandas\"->datadotworld[pandas])\n",
      "Requirement already satisfied: jdcal in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from openpyxl<3.0,>=2.4->tabulator<=1.4.1->datadotworld[pandas])\n",
      "Requirement already satisfied: et_xmlfile in /Users/jameswilfong/anaconda/lib/python3.6/site-packages (from openpyxl<3.0,>=2.4->tabulator<=1.4.1->datadotworld[pandas])\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 18.0 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<a id='notebook-config'></a>\n",
       "## Notebook Config\n",
       "* python-dotenv\n",
       "* datadotworld"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%env\n",
    "\n",
    "cell_log.clear()\n",
    "cell_log.collect(\"<a id='notebook-config'></a>\")\n",
    "cell_log.collect(\"## Notebook Config\")\n",
    "# ------------ environment variable magic\n",
    "\n",
    "# Install a pip packages in the current Jupyter kernel\n",
    "# ------------ Python-dotenv\n",
    "cell_log.collect(\"* python-dotenv\")\n",
    "import sys\n",
    "!{sys.executable} -m pip install python-dotenv\n",
    "# ------------ data.world API \n",
    "cell_log.collect(\"* datadotworld\")\n",
    "!{sys.executable} -m pip install datadotworld[pandas]\n",
    "\n",
    "Markdown('''{}'''.format(cell_log.getMarkdown()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process\n",
    "## Prepare Data\n",
    "* download github repo with data\n",
    "* put new file in raw-data/\n",
    "* make copy of this jupyter notebook \n",
    "* configure to transform raw-data/ into clean-data/\n",
    "* put clean data into clean/ folder\n",
    "* push final changes to github\n",
    "## Load Data\n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='wrangling_steps'></a>\n",
    "# Data Wrangling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='wrangle-process'></a>\n",
    "## Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"download\"></a>\n",
    "# Download Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "table_name: gr_drains\n",
       "* ext: csv\n",
       "* table_name: GRB Storm Drains\n",
       "* desc: Storm Drains of the Grand River Basin, Michigan\n",
       "* DW_USER: wilfongjt\n",
       "* DW_DB_URL: https://api.data.world/v0/datasets/wilfongjt/\n",
       "* GH_URL: https://raw.githubusercontent.com/Wilfongjt/source-data/refresh-data/clean-data/\n",
       "* LOCAL_SCRIPT_FOLDER: /Users/jameswilfong/Documents/Github/Wilfongjt/source-data/scripts/adopt-a-drain\n",
       "* LOCAL_APP_NAME: adopt-a-drain\n",
       "* LOCAL_REPO_FOLDER: /Users/jameswilfong/Documents/Github/Wilfongjt/source-data\n",
       "* LOCAL_REPO_BRANCH: refresh-data\n",
       "* LOCAL_RAW_FOLDER: /Users/jameswilfong/Documents/Github/Wilfongjt/source-data/raw-data/adopt-a-drain\n",
       "* LOCAL_CLEAN_FOLDER: /Users/jameswilfong/Documents/Github/Wilfongjt/source-data/clean-data/adopt-a-drain"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell_log.clear()\n",
    "# dev stops github and data.world updates\n",
    "# prod allows github and data.world updates\n",
    "# MODE='prod' # dev, prod\n",
    "'''\n",
    "------------- configure raw-data\n",
    "'''\n",
    "\n",
    "table_name = 'gr_drains'\n",
    "cell_log.collect('table_name: {}'.format(table_name))\n",
    "\n",
    "ext = 'csv'\n",
    "cell_log.collect('* ext: {}'.format(ext))\n",
    "\n",
    "title_name = 'GRB Storm Drains'\n",
    "cell_log.collect('* table_name: {}'.format(title_name))\n",
    "\n",
    "desc = 'Storm Drains of the Grand River Basin, Michigan'\n",
    "cell_log.collect('* desc: {}'.format(desc))\n",
    "\n",
    "cell_log.collect('* DW_USER: {}'.format(DW_USER))\n",
    "cell_log.collect('* DW_DB_URL: {}'.format(DW_DB_URL))\n",
    "cell_log.collect('* GH_URL: {}'.format(GH_URL))\n",
    "\n",
    "\n",
    "'''\n",
    "-------------- setup GitHub\n",
    "'''\n",
    "LOCAL_REPO_BRANCH = 'refresh-data'\n",
    "\n",
    "'''\n",
    "------------- setup constants to GitHub folders\n",
    "'''\n",
    "\n",
    "LOCAL_SCRIPT_FOLDER = os.getcwd()\n",
    "LOCAL_APP_NAME = get_app_name(LOCAL_SCRIPT_FOLDER)\n",
    "LOCAL_REPO_FOLDER =  get_repo_folder(LOCAL_SCRIPT_FOLDER)  \n",
    "LOCAL_RAW_FOLDER = get_raw_data_folder(LOCAL_SCRIPT_FOLDER) \n",
    "LOCAL_CLEAN_FOLDER = get_clean_data_folder(LOCAL_SCRIPT_FOLDER)\n",
    "\n",
    "cell_log.collect('* LOCAL_SCRIPT_FOLDER: {}'.format(LOCAL_SCRIPT_FOLDER))\n",
    "cell_log.collect('* LOCAL_APP_NAME: {}'.format(LOCAL_APP_NAME))\n",
    "cell_log.collect('* LOCAL_REPO_FOLDER: {}'.format(LOCAL_REPO_FOLDER))\n",
    "cell_log.collect('* LOCAL_REPO_BRANCH: {}'.format(LOCAL_REPO_BRANCH))\n",
    "cell_log.collect('* LOCAL_RAW_FOLDER: {}'.format(LOCAL_RAW_FOLDER))\n",
    "cell_log.collect('* LOCAL_CLEAN_FOLDER: {}'.format(LOCAL_CLEAN_FOLDER))\n",
    "\n",
    "Markdown('''{}'''.format(cell_log.getMarkdown()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package Configuration for Convenence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dw_dataset_id = DW_USER + \"/\" + title_name.lower().replace('_','-').replace(' ','-')\n",
    "gh_csv_name = table_name\n",
    "gh_csv_name_ext = gh_csv_name + '.' + ext\n",
    "gh_csv_path_name = GH_URL + gh_csv_name_ext\n",
    "\n",
    "'''\n",
    "------------- configure source csv\n",
    "'''\n",
    "\n",
    "tbl = { \"owner_id\": DW_USER, \n",
    "        \"app_name\": LOCAL_APP_NAME,\n",
    "             \"dw_title\": title_name, \n",
    "             \"dw_desc\": desc,\n",
    "             \"dw_table\": table_name,\n",
    "             \"dw_dataset_id\": dw_dataset_id,\n",
    "             \"dw_url\": DW_DB_URL + table_name + '.' + ext,\n",
    "             \"gh_url\": GH_URL + table_name, \n",
    "             \"visibility\": \"OPEN\", \n",
    "             \"license\": \"Public Domain\",\n",
    "             \"files\": {table_name + '.' + 'csv': {\"url\": gh_csv_path_name }},\n",
    "             \"local_raw\": LOCAL_RAW_FOLDER + '/' + gh_csv_name_ext,\n",
    "             \"local_clean\": LOCAL_CLEAN_FOLDER + '/' + gh_csv_name_ext,\n",
    "           }\n",
    "'''\n",
    "------------- configure outliers\n",
    "'''\n",
    "_outliers = {\n",
    "  'outliers': [\n",
    "    {'column':'dr_facility_id',\n",
    "     'range':(1, 50000000),\n",
    "     'reason':'ignore {} outliers (1 <= dr_facility_id or => 50000000).',\n",
    "     'count': 0\n",
    "    }, \n",
    "    {'column':'dr_lon',\n",
    "     'range':(-90.0, -80.0),\n",
    "     'reason':'Remove {} observations too far west or east.',\n",
    "     'count': 0\n",
    "    },  \n",
    "    {'column':'dr_lat',\n",
    "     'range':(40.0, 50.0),\n",
    "     'reason':'Remove {} observations too far north or south.',\n",
    "     'count': 0\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "# pprint( tbl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrangling Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* clean_column_names: 0.007170915603637695 sec\n",
      "* remove_obvious_outliers: 0.015781879425048828 sec\n"
     ]
    }
   ],
   "source": [
    "cell_log.clear()\n",
    "\n",
    "cell_log.collect(\"# CSV Process\")\n",
    "'''\n",
    "--------------------------------- input\n",
    "'''\n",
    "cell_log.collect(\"* input:  {}\".format( tbl[\"local_raw\"]))\n",
    "'''\n",
    "--------------------------------- load data\n",
    "'''\n",
    "df_source = getSourceData(tbl) # open raw-data\n",
    "cell_log.collect(\"* input: {} observations\".format(len(df_source)))\n",
    "cell_log.collect(\"* input: columns {}\".format(df_source.columns.values))\n",
    "\n",
    "'''\n",
    "--------------------------------- clean column names\n",
    "'''\n",
    "cell_log.collect('* format: Apply a style of lowercase and underscores to column names.')##############################\n",
    "df_source = clean.clean_column_names(df_source) # column names\n",
    "\n",
    "'''\n",
    "--------------------------------- map expected colums to raw-data columns\n",
    "'''\n",
    "df_source = df_source.rename(columns={ # rename columns in df\n",
    "    \"subtype\": \"dr_subtype\",\n",
    "    \"drain__owner\": \"dr_owner\",\n",
    "    \"local__id\": \"dr_local_id\",\n",
    "    \"facilityid\": \"dr_facility_id\",\n",
    "    \"drain__jurisdiction\": \"dr_jurisdiction\",\n",
    "    \"subwatershed\": \"dr_subwatershed\",\n",
    "    \"point__x\":\"dr_lon\", \n",
    "    \"point__y\":\"dr_lat\"})\n",
    "\n",
    "'''\n",
    "--------------------------------- change empty values\n",
    "'''\n",
    "\n",
    "## ------------------------------ DROP empty Facility id\n",
    "# mark all empties with same value\n",
    "df_source['dr_facility_id'] = df_source['dr_facility_id'].apply(lambda x:  np.nan if x != x or x == '' or x == ' ' or x == None else x)\n",
    "scnt = len(df_source)\n",
    "df_source = df_source.dropna(subset=['dr_facility_id', 'soure__id','dr_lon', 'dr_lat'])\n",
    "ecnt = len(df_source)\n",
    "cell_log.collect(\"* clean: dropped {} observations with empty dr_facility_id, soure___id, dr_lon, or dr_lat\".format(scnt - ecnt))\n",
    "\n",
    "'''\n",
    "--------------------------------- change column types\n",
    "'''\n",
    "cell_log.collect('* format: convert dr_facility_id column to int64')\n",
    "df_source['dr_facility_id'] = df_source['dr_facility_id'].astype('int64')\n",
    "\n",
    "'''\n",
    "--------------------------------- remove numbers from df_source_id\n",
    "'''\n",
    "\n",
    "df_source['soure__id'] = df_source['soure__id'].apply(lambda x: x.split('_')[0] + '_' if isinstance(x, str) else 'XXX_') \n",
    "\n",
    "df_source['dr_asset_no'] = df_source['dr_facility_id']\n",
    "df_source['dr_type'] = df_source['dr_facility_id'].apply(lambda x: 'Storm Water Inlet Drain')\n",
    "'''\n",
    "--------------------------------- create a sync id\n",
    "'''\n",
    "df_source['dr_sync_id'] = df_source['soure__id'] + df_source['dr_facility_id'].astype(str)\n",
    "\n",
    "'''\n",
    "--------------------------------- drop soure__id\n",
    "'''\n",
    "df_source = df_source.drop(['soure__id'], axis=1)\n",
    "\n",
    "'''\n",
    "--------------------------------- outliers\n",
    "'''\n",
    "df_source = clean.remove_obvious_outliers(_outliers, df_source)\n",
    "for r in _outliers['outliers']:\n",
    "    cell_log.collect('* outlier: {}'.format(r['reason']))\n",
    "\n",
    "'''\n",
    "--------------------------------- Drop DUPLICATES\n",
    "'''\n",
    "scnt = len(df_source)\n",
    "df_source = df_source.drop_duplicates('dr_facility_id',keep=False)\n",
    "ecnt = len(df_source)\n",
    "cell_log.collect('* duplicates: dropped {} duplicate facility ids'.format(scnt - ecnt))\n",
    "\n",
    "\n",
    "'''\n",
    "--------------------------------- save csv \n",
    "'''\n",
    "# assume new file and remove old one\n",
    "if os.path.isfile(tbl[\"local_clean\"]):\n",
    "    os.remove(tbl['local_clean'])\n",
    "    cell_log.collect('* system: overwrite {} '.format(tbl['local_clean']))\n",
    "\n",
    "cell_log.collect(\"* inter-output: columns {}\".format(df_source.columns.values))\n",
    "cell_log.collect('* inter-output: {} obs to {}'.format(len(df_source) , tbl[\"local_clean\"]))\n",
    "\n",
    "\n",
    "df_source.to_csv(tbl[\"local_clean\"], index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interface with GitHub and Data.World"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# CSV Process\n",
       "* input:  /Users/jameswilfong/Documents/Github/Wilfongjt/source-data/raw-data/adopt-a-drain/gr_drains.csv\n",
       "* input: 40204 observations\n",
       "* input: columns ['SUBTYPE' 'DRAIN_JURISDICTION' 'DRAIN_OWNER' 'Soure_ID' 'LOCAL_ID'\n",
       " 'FACILITYID' 'Subwatershed' 'POINT_X' 'POINT_Y']\n",
       "* format: Apply a style of lowercase and underscores to column names.\n",
       "* clean: dropped 15 observations with empty dr_facility_id, soure___id, dr_lon, or dr_lat\n",
       "* format: convert dr_facility_id column to int64\n",
       "* outlier: ignore 0 outliers (1 <= dr_facility_id or => 50000000).\n",
       "* outlier: Remove 0 observations too far west or east.\n",
       "* outlier: Remove 0 observations too far north or south.\n",
       "* duplicates: dropped 225 duplicate facility ids\n",
       "* system: overwrite /Users/jameswilfong/Documents/Github/Wilfongjt/source-data/clean-data/adopt-a-drain/gr_drains.csv \n",
       "* inter-output: columns ['dr_subtype' 'dr_jurisdiction' 'dr_owner' 'dr_local_id' 'dr_facility_id'\n",
       " 'dr_subwatershed' 'dr_lon' 'dr_lat' 'dr_asset_no' 'dr_type' 'dr_sync_id']\n",
       "* inter-output: 39964 obs to /Users/jameswilfong/Documents/Github/Wilfongjt/source-data/clean-data/adopt-a-drain/gr_drains.csv\n",
       "\n",
       "# GIT Process\n",
       "* input: /Users/jameswilfong/Documents/Github/Wilfongjt/source-data/clean-data/adopt-a-drain/gr_drains.csv\n",
       "* git add ../../raw-data -A\n",
       "* git add ../../clean-data -A\n",
       "* git add ../../scripts -A\n",
       "* git add ../../README.md -A\n",
       "* git commit -m \"update raw-data, clean-data, and scripts\"\n",
       "\n",
       "# Data.World Process\n",
       "* input: https://raw.githubusercontent.com/Wilfongjt/source-data/refresh-data/clean-data/gr_drains.csv\n",
       "* load: 39964 observations\n",
       "* drop: wilfongjt/grb-storm-drains\n",
       "* delay: 6 seconds to delete data\n",
       "* load: complete\n",
       "* output: https://api.data.world/v0/datasets/wilfongjt/gr_drains.csv"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interface.github(df_source, tbl, cell_log)\n",
    "\n",
    "interface.data_world(df_source, tbl, cell_log)\n",
    "\n",
    "Markdown('''{}'''.format(cell_log.getMarkdown()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Appendix - Data.World Names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keeping the names straight\n",
    "\n",
    "| CSV Name      | Table Name    | Title          | Dataset ID      | Restful |\n",
    "| :------------ |:------------- | :------------- | :-------------  | :------------- |\n",
    "| xxxx_xx       | xxxx_xx       | Xxxx Xx        | xxxx-xx         |    ?     | \n",
    "| xxxx_xx       | xxxx_xx       | Xxxx_Xx        | xxxxxx          |    ?            |\n",
    "| xxxx_xx       | xxxx_xx       | Xxxx-Xx        | xxxx-xx         |    ?         |\n",
    "| xxxx-xx       | xxxx_xx       | Xxxx Xx        | xxxx-xx         |    ?         |\n",
    "| xxxx-xx       | xxxx_xx       | Xxxx_Xx        | xxxxxx          |    ?         |\n",
    "| xxxx-xx       | xxxx_xx       | Xxxx-Xx        | xxxx-xx         |    ?         |\n",
    "\n",
    "* CSV Name is root of Table name\n",
    "* Title is root of Dataset ID\n",
    "* a space in Title will be automatically converted to hyphen in dataset id\n",
    "* an underscore in Title will be removed in Dataset ID\n",
    "* a hyphen in CSV Name will be replaced with underscore in Table Name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
